{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<p align=\"center\">\n",
    "    <img src=\"https://vectorseek.com/wp-content/uploads/2023/12/Mistral-AI-Icon-Logo-Vector.svg-.png\" alt=\"Mistral.ai\" width=\"40\" style=\"margin-right: 20px;\" align=\"center\">\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/2/2d/Tensorflow_logo.svg\" alt=\"TensorFlow\" width=\"35\" align=\"center\">\n",
    "</p>\n",
    "<h1 align=\"center\">Estimation de la note d'un commentaire avec Mistral.ai, XGBoost et TensorFlow</h1>\n",
    "\n",
    "---\n",
    "\n",
    "Ce notebook est un outil d'exploration qui vise à étudier la possibilité d'utiliser les embeddings fournies par Mistral pour prédire la note associée à un commentaire. Pour accélérer le traitement des commentaires et de leurs embeddings, nous utiliserons la méthode des chunks. Cette approche consiste à diviser les données en plusieurs morceaux, ce qui permet de gérer les données de manière plus efficace et rapide.\n",
    "\n",
    "Une fois les embeddings récupérées, nous utiliserons deux méthodes distinctes pour entraîner notre modèle de prédiction : \n",
    "- XGBoost \n",
    "- TensorFlow \n",
    "\n",
    "**XGBoost** est un algorithme de gradient boosting qui a fait ses preuves dans de nombreux domaines d'application, notamment pour la classification et la régression. <br>\n",
    "<p align=\"center\">\n",
    "    <img src=\"https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fdzone.com%2Fstorage%2Ftemp%2F13069527-boosting-algo.png&f=1&nofb=1&ipt=1ac6f470930257e0fb83997b0768a166f0c2b93a8ecd29dfc184c95efd1e786d&ipo=images\" alt=\"XGBoost\" width=\"500\">\n",
    "</p>\n",
    "\n",
    "**TensorFlow** est une bibliothèque open source pour l'apprentissage automatique qui permet de créer des réseaux de neurones profonds et complexes.\n",
    "<p align=\"center\">\n",
    "    <img src=\"https://s3.amazonaws.com/stackabuse/media/intro-to-neural-networks-scikit-learn-3.png\" alt=\"neural network\" width=\"300\">\n",
    "</p>\n",
    "Dans un premier temps, nous préparerons les données en effectuant un prétraitement des commentaires et en récupérant les embeddings associées. Nous diviserons ensuite les données en un ensemble d'entraînement et un ensemble de test, ce qui nous permettra d'évaluer les performances de notre modèle. \n",
    "\n",
    "Nous entraînerons ensuite notre modèle à l'aide des deux méthodes mentionnées précédemment. Pour XGBoost, nous utiliserons l'algorithme de classification pour prédire la note associée à chaque commentaire. Pour TensorFlow, nous créerons un réseau de neurones profond avec plusieurs couches cachées et une couche de sortie avec cinq neurones, correspondant aux cinq notes possibles.\n",
    "\n",
    "Enfin, nous évaluerons les performances de notre modèle sur l'ensemble de test en utilisant des métriques telles que la précision, le rappel et le score F1. Nous comparerons également les performances des deux méthodes pour déterminer celle qui convient le mieux à notre problème.\n",
    "\n",
    "Dans l'ensemble, ce notebook vise à explorer la faisabilité d'utiliser les embeddings fournies par Mistral pour prédire la note associée à un commentaire. En utilisant deux méthodes distinctes, nous chercherons à déterminer la meilleure approche pour résoudre ce problème et à évaluer les performances de notre modèle.\n",
    "\n",
    "---\n",
    "\n",
    "# Installation et importation des packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -U xgboost scikit-learn mistralai tensorflow pandas numpy\n",
    "from mistralai.client import MistralClient\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation de la base de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = pd.read_csv(\"singapore_airlines_reviews.csv\")\n",
    "data = review.drop(columns=[\"published_date\", \"published_platform\", \"type\", \"title\", \"helpful_votes\"])\n",
    "data = data.head(2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Définition de la méthode d'Embeddings\n",
    "\n",
    "Mise en place de la fonction d'embeddings :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MistralClient(api_key=\"TVgCvsfUiqr5m8F1JSleadiEpHF5UdhL\")\n",
    "\n",
    "def get_embeddings_by_chunks(data, chunk_size):\n",
    "    chunks = [data[x : x + chunk_size] for x in range(0, len(data), chunk_size)]\n",
    "    embeddings_response = [\n",
    "        client.embeddings(model=\"mistral-embed\", input=c) for c in chunks\n",
    "    ]\n",
    "    return [d.embedding for e in embeddings_response for d in e.data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Application de la fonction d'embeddings :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"embeddings\"] = get_embeddings_by_chunks(data[\"text\"].tolist(), 10)\n",
    "#np.array(data[\"embeddings\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prépatation des données d'entrainement et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(np.array(np.array(data[\"embeddings\"]).tolist()), np.array(data[\"rating\"]), test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision sur l'ensemble de test : 0.74\n"
     ]
    }
   ],
   "source": [
    "# Entraînement du modèle\n",
    "\n",
    "# Définir les paramètres du modèle XGBoost\n",
    "params = {\n",
    "    'objective': 'multi:softprob',\n",
    "    'eval_metric': 'mlogloss',\n",
    "    'num_class': 6,\n",
    "    'max_depth': 3,\n",
    "    'eta': 0.1,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8\n",
    "}\n",
    "\n",
    "# Convertir les données en formats DMatrix de XGBoost\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Entraîner le modèle XGBoost\n",
    "model = xgb.train(params, dtrain, num_boost_round=100)\n",
    "\n",
    "# Évaluation du modèle\n",
    "\n",
    "# Évaluer le modèle sur l'ensemble de test\n",
    "y_pred = model.predict(dtest)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(\"Précision sur l'ensemble de test : {:.2f}\".format(accuracy))\n",
    "\n",
    "precision, recall, fscore, support = precision_recall_fscore_support(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jbastruz/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - accuracy: 0.4856 - loss: 1.3041 - val_accuracy: 0.7125 - val_loss: 0.7075\n",
      "Epoch 2/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6685 - loss: 0.8329 - val_accuracy: 0.6938 - val_loss: 0.7180\n",
      "Epoch 3/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7140 - loss: 0.7584 - val_accuracy: 0.6938 - val_loss: 0.7507\n",
      "Epoch 4/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7157 - loss: 0.7743 - val_accuracy: 0.7625 - val_loss: 0.6312\n",
      "Epoch 5/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7302 - loss: 0.7186 - val_accuracy: 0.7500 - val_loss: 0.6856\n",
      "Epoch 6/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7345 - loss: 0.7517 - val_accuracy: 0.7375 - val_loss: 0.6657\n",
      "Epoch 7/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7372 - loss: 0.6854 - val_accuracy: 0.7312 - val_loss: 0.6324\n",
      "Epoch 8/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7507 - loss: 0.6260 - val_accuracy: 0.7437 - val_loss: 0.5818\n",
      "Epoch 9/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7700 - loss: 0.5940 - val_accuracy: 0.7500 - val_loss: 0.6674\n",
      "Epoch 10/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7727 - loss: 0.6255 - val_accuracy: 0.7437 - val_loss: 0.6031\n",
      "Epoch 11/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7682 - loss: 0.6238 - val_accuracy: 0.7625 - val_loss: 0.6056\n",
      "Epoch 12/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8010 - loss: 0.5431 - val_accuracy: 0.8062 - val_loss: 0.6013\n",
      "Epoch 13/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7842 - loss: 0.5600 - val_accuracy: 0.7188 - val_loss: 0.7672\n",
      "Epoch 14/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7567 - loss: 0.6058 - val_accuracy: 0.8000 - val_loss: 0.5785\n",
      "Epoch 15/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7890 - loss: 0.5606 - val_accuracy: 0.7188 - val_loss: 0.6731\n",
      "Epoch 16/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8026 - loss: 0.5302 - val_accuracy: 0.7688 - val_loss: 0.6097\n",
      "Epoch 17/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8136 - loss: 0.5154 - val_accuracy: 0.7500 - val_loss: 0.6662\n",
      "Epoch 18/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7757 - loss: 0.5726 - val_accuracy: 0.7563 - val_loss: 0.6266\n",
      "Epoch 19/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7818 - loss: 0.5322 - val_accuracy: 0.7500 - val_loss: 0.6083\n",
      "Epoch 20/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7968 - loss: 0.5048 - val_accuracy: 0.7875 - val_loss: 0.6380\n",
      "Epoch 21/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8152 - loss: 0.4893 - val_accuracy: 0.7688 - val_loss: 0.6182\n",
      "Epoch 22/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8239 - loss: 0.4748 - val_accuracy: 0.7875 - val_loss: 0.5843\n",
      "Epoch 23/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8307 - loss: 0.4562 - val_accuracy: 0.7312 - val_loss: 0.7455\n",
      "Epoch 24/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8174 - loss: 0.4923 - val_accuracy: 0.7875 - val_loss: 0.6037\n",
      "Epoch 25/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.8259 - loss: 0.4698 - val_accuracy: 0.7563 - val_loss: 0.6331\n",
      "Epoch 26/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.7956 - loss: 0.4766 - val_accuracy: 0.7500 - val_loss: 0.6042\n",
      "Epoch 27/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.8208 - loss: 0.4857 - val_accuracy: 0.7312 - val_loss: 0.7440\n",
      "Epoch 28/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.7996 - loss: 0.4988 - val_accuracy: 0.7688 - val_loss: 0.6348\n",
      "Epoch 29/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8168 - loss: 0.4797 - val_accuracy: 0.7750 - val_loss: 0.6386\n",
      "Epoch 30/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8675 - loss: 0.3983 - val_accuracy: 0.7812 - val_loss: 0.6687\n",
      "Epoch 31/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.8390 - loss: 0.4405 - val_accuracy: 0.8000 - val_loss: 0.6964\n",
      "Epoch 32/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.8028 - loss: 0.4777 - val_accuracy: 0.7500 - val_loss: 0.6916\n",
      "Epoch 33/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.8532 - loss: 0.4064 - val_accuracy: 0.7563 - val_loss: 0.8318\n",
      "Epoch 34/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8067 - loss: 0.4896 - val_accuracy: 0.7750 - val_loss: 0.6259\n",
      "Epoch 35/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8540 - loss: 0.4065 - val_accuracy: 0.6687 - val_loss: 0.8360\n",
      "Epoch 36/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8319 - loss: 0.4459 - val_accuracy: 0.7750 - val_loss: 0.7144\n",
      "Epoch 37/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8337 - loss: 0.4457 - val_accuracy: 0.7500 - val_loss: 0.7164\n",
      "Epoch 38/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8665 - loss: 0.3775 - val_accuracy: 0.7750 - val_loss: 0.7124\n",
      "Epoch 39/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8596 - loss: 0.3768 - val_accuracy: 0.7188 - val_loss: 0.7307\n",
      "Epoch 40/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8580 - loss: 0.4011 - val_accuracy: 0.7812 - val_loss: 0.7008\n",
      "Epoch 41/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8808 - loss: 0.3507 - val_accuracy: 0.7312 - val_loss: 0.8823\n",
      "Epoch 42/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8683 - loss: 0.3811 - val_accuracy: 0.7375 - val_loss: 0.7567\n",
      "Epoch 43/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8765 - loss: 0.3404 - val_accuracy: 0.7375 - val_loss: 0.8214\n",
      "Epoch 44/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8568 - loss: 0.4072 - val_accuracy: 0.7688 - val_loss: 0.7796\n",
      "Epoch 45/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8685 - loss: 0.3576 - val_accuracy: 0.7188 - val_loss: 0.9434\n",
      "Epoch 46/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8749 - loss: 0.3574 - val_accuracy: 0.7188 - val_loss: 0.7626\n",
      "Epoch 47/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8497 - loss: 0.4407 - val_accuracy: 0.7750 - val_loss: 0.7067\n",
      "Epoch 48/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8905 - loss: 0.3203 - val_accuracy: 0.7563 - val_loss: 0.6843\n",
      "Epoch 49/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8918 - loss: 0.3059 - val_accuracy: 0.7625 - val_loss: 0.8125\n",
      "Epoch 50/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8887 - loss: 0.3261 - val_accuracy: 0.7312 - val_loss: 0.7832\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Erreur quadratique moyenne sur l'ensemble de test : 0.41\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(np.array(np.array(data[\"embeddings\"]).tolist()), np.array(data[\"rating\"]), test_size=0.2, random_state=42)\n",
    "\n",
    "y_train = y_train - 1\n",
    "y_test = y_test - 1\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1024, activation='tanh', input_shape=(1024,)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(512, activation='tanh'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(256, activation='tanh'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(128, activation='tanh'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(64, activation='tanh'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(32, activation='tanh'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compiler le modèle Keras\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "\n",
    "# Entraîner le modèle Keras\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Évaluation du modèle\n",
    "\n",
    "# Évaluer le modèle sur l'ensemble de test\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "mse = ((y_test - y_pred) ** 2).mean()\n",
    "print(\"Erreur quadratique moyenne sur l'ensemble de test : {:.2f}\".format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 3 5 1 4 4 1 2 2 5 1 5 2 3 1 3 1 3 3 4 2 5 5 5 5 1 1 3 4 3 1 1 1 1 1 5 3\n",
      " 5 5 5 5 5 5 3 5 4 1 4 5 5 5 1 4 1 1 5 1 5 1 3 5 5 5 1 5 5 3 3 2 1 3 3 5 1\n",
      " 1 5 5 1 1 5 5 1 5 2 5 4 5 2 5 5 5 4 3 2 5 5 3 1 5 1 1 1 1 4 3 5 1 5 1 2 1\n",
      " 5 4 2 3 5 2 1 3 5 4 5 5 5 3 5 1 1 1 2 4 4 1 1 1 1 2 5 5 5 1 3 5 1 5 5 1 1\n",
      " 1 1 5 1 1 2 1 1 5 5 3 3 5 1 5 1 5 5 5 4 2 5 5 1 5 5 1 1 2 1 1 5 5 4 1 1 3\n",
      " 1 4 4 1 1 2 5 5 5 5 4 5 1 1 3 5 5 5 1 4 2 5 5 1 2 5 1 2 1 3 5 4 4 1 5 1 1\n",
      " 1 1 5 5 3 5 5 1 5 1 5 5 3 1 5 1 5 5 1 5 3 1 3 4 5 4 1 5 2 1 1 4 1 2 1 5 4\n",
      " 2 2 5 2 5 1 5 1 3 5 1 3 1 1 5 1 5 1 5 4 1 5 1 1 5 5 4 1 5 5 5 1 3 4 5 5 1\n",
      " 3 5 3 1 5 1 5 2 1 4 1 5 1 4 1 5 3 1 2 2 5 5 5 4 1 4 3 4 3 1 5 1 5 1 1 1 5\n",
      " 5 5 3 1 2 1 5 1 5 1 1 1 5 2 5 5 3 4 1 4 3 1 2 5 4 1 1 5 3 5 5 1 4 5 2 1 1\n",
      " 5 5 3 5 5 4 3 5 5 5 5 1 1 1 5 1 1 1 5 5 4 4 1 1 3 1 5 5 1 2]\n",
      "[5 3 5 2 4 4 2 3 2 5 1 5 3 5 1 2 1 4 4 4 2 5 4 5 5 1 1 4 5 2 1 2 3 2 2 5 3\n",
      " 4 5 5 5 5 5 1 5 4 1 3 5 5 5 1 5 1 1 5 1 4 1 4 5 5 5 1 5 5 2 4 2 1 4 2 5 1\n",
      " 1 5 5 1 1 5 5 2 5 2 5 4 5 1 5 5 4 4 3 2 5 5 3 1 5 1 1 2 1 5 3 5 1 5 2 2 2\n",
      " 5 4 1 1 5 1 1 3 5 4 4 5 5 4 5 3 1 1 2 4 4 2 1 1 1 1 5 5 5 1 3 4 1 5 5 1 1\n",
      " 1 1 5 1 1 1 2 1 5 5 3 2 5 2 5 1 5 5 5 4 2 5 5 1 5 4 2 1 4 1 1 5 5 4 2 1 4\n",
      " 1 4 5 1 1 1 5 5 5 5 4 5 1 1 3 5 5 4 2 5 3 4 5 1 3 5 1 2 1 1 4 5 2 1 5 1 1\n",
      " 1 1 5 5 3 5 5 1 5 2 5 5 3 2 4 2 5 5 1 5 2 1 3 5 5 5 1 5 1 2 1 3 1 2 1 5 5\n",
      " 1 2 4 1 4 1 5 1 1 5 1 3 2 1 5 3 5 1 5 4 1 4 1 1 5 5 4 1 5 5 5 1 5 5 5 5 1\n",
      " 3 5 4 1 5 1 5 2 1 4 1 5 1 3 1 5 2 1 1 3 5 5 5 4 2 5 3 3 1 3 5 1 5 1 1 2 5\n",
      " 5 5 3 1 1 1 5 1 5 2 1 1 5 3 4 4 1 4 1 4 4 2 1 5 4 1 1 5 3 5 5 1 4 5 4 3 1\n",
      " 5 5 1 4 4 3 3 5 5 5 4 1 2 1 5 1 1 1 5 5 5 4 1 1 3 2 5 5 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred + 1)\n",
    "print(y_test + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, fscore, support = precision_recall_fscore_support(y_test+1, y_pred+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classe 1 : Précision = 0.77, Rappel = 0.84, Fscore = 0.80\n",
      "Classe 2 : Précision = 0.36, Rappel = 0.26, Fscore = 0.30\n",
      "Classe 3 : Précision = 0.42, Rappel = 0.54, Fscore = 0.47\n",
      "Classe 4 : Précision = 0.56, Rappel = 0.43, Fscore = 0.48\n",
      "Classe 5 : Précision = 0.87, Rappel = 0.90, Fscore = 0.89\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(precision)):\n",
    "    print(f\"Classe {i+1} : Précision = {precision[i]:.2f}, Rappel = {recall[i]:.2f}, Fscore = {fscore[i]:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
